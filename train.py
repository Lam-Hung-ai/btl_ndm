import json
import os

import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision.datasets import CIFAR10
from torchvision.transforms import ToTensor
from tqdm import tqdm

from early_stop import EarlyStopping
from resnet import ResNet152, ResNet18, ResNet34, ResNet50, ResNet101

# --- 1. Táº­p dá»¯ liá»‡u ---
batch_size = 512
train = CIFAR10(root="cifar_10/", train=True, transform=ToTensor(), download=False)
test = CIFAR10(root="cifar_10/", train=False, transform=ToTensor(), download=False)

train_dataloader = DataLoader(train, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=3)
test_dataloader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=3)

# --- 2. Thiáº¿t láº­p mÃ´ hÃ¬nh ---
device = "cuda" if torch.cuda.is_available() else "cpu"
model = ResNet152().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

# --- 3. ThÃ´ng sá»‘ huáº¥n luyá»‡n ---
epochs = 60
loss_info = {
    "train_loss": [],
    "train_acc": [],
    "test_loss": [],
    "test_acc": []
}

# --- 4. ThÆ° má»¥c lÆ°u trá»ng sá»‘ ---
os.makedirs("weights", exist_ok=True)
os.makedirs("images", exist_ok=True)
early_stopper = EarlyStopping(patience=10, verbose=False)
best_acc = 0.0

# --- 5. VÃ²ng láº·p huáº¥n luyá»‡n ---
for epoch in range(epochs):
    model.train()
    total_train_loss = 0.0
    correct_train = 0
    total_train = 0

    for images, labels in tqdm(train_dataloader, desc=f"Epoch {epoch+1}/{epochs} - Äang huáº¥n luyá»‡n", leave=False):
        images = images.to(device)
        labels = labels.to(device)

        # lan truyá»n xuÃ´i (forward)
        outputs = model(images)
        loss = criterion(outputs, labels)

        # lan truyá»n ngÆ°á»£c (backward)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # ghi nháº­n chá»‰ sá»‘ huáº¥n luyá»‡n
        total_train_loss += loss.item() * images.size(0)
        _, predicted = outputs.max(1)
        correct_train += (predicted == labels).sum().item()
        total_train += labels.size(0)

    avg_train_loss = total_train_loss / total_train
    train_accuracy = correct_train / total_train

    # --- ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh ---
    model.eval()
    total_test_loss = 0.0
    correct_test = 0
    total_test = 0

    with torch.no_grad():
        for images, labels in tqdm(test_dataloader, desc=f"Epoch {epoch+1}/{epochs} - Äang kiá»ƒm tra", leave=False):
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)

            total_test_loss += loss.item() * images.size(0)
            _, predicted = outputs.max(1)
            correct_test += (predicted == labels).sum().item()
            total_test += labels.size(0)

    avg_test_loss = total_test_loss / total_test
    test_accuracy = correct_test / total_test

    # --- LÆ°u thÃ´ng tin huáº¥n luyá»‡n ---
    loss_info["train_loss"].append(avg_train_loss)
    loss_info["train_acc"].append(train_accuracy)
    loss_info["test_loss"].append(avg_test_loss)
    loss_info["test_acc"].append(test_accuracy)

    print(f"[Epoch {epoch+1:03d}/{epochs}] "
          f"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f}, "
          f"Test Loss: {avg_test_loss:.4f}, Test Acc: {test_accuracy:.4f}")

    # --- LÆ°u trá»ng sá»‘ ---
    torch.save(model.state_dict(),f"weights/{model.name}_last.pth")

    if test_accuracy > best_acc:
        best_acc = test_accuracy
        torch.save(model.state_dict(), f"weights/{model.name}_best.pth")
        print(f"âœ… MÃ´ hÃ¬nh tá»‘t nháº¥t má»›i Ä‘Æ°á»£c lÆ°u vá»›i Ä‘á»™ chÃ­nh xÃ¡c {best_acc:.4f}")

    early_stopper(avg_test_loss)
    if early_stopper.should_stop:
        print("ğŸ›‘ Dá»«ng sá»›m Ä‘Æ°á»£c kÃ­ch hoáº¡t!")
        break

# --- 6. Tá»•ng káº¿t ---
print("\nğŸ‰ QuÃ¡ trÃ¬nh huáº¥n luyá»‡n hoÃ n táº¥t!")
print(f"Äá»™ chÃ­nh xÃ¡c kiá»ƒm tra tá»‘t nháº¥t: {best_acc:.4f}")

# --- 7. Váº½ biá»ƒu Ä‘á»“ máº¥t mÃ¡t vÃ  Ä‘á»™ chÃ­nh xÃ¡c ---
epochs_done = len(loss_info["train_loss"])
epochs_range = range(1, epochs_done + 1)

plt.figure(figsize=(12, 5))

# Máº¥t mÃ¡t (Loss)
plt.subplot(1, 2, 1)
plt.plot(epochs_range, loss_info["train_loss"], label="Máº¥t mÃ¡t huáº¥n luyá»‡n")
plt.plot(epochs_range, loss_info["test_loss"], label="Máº¥t mÃ¡t kiá»ƒm tra")
plt.title("Biá»ƒu Ä‘á»“ máº¥t mÃ¡t qua cÃ¡c epoch")
plt.xlabel("Epoch")
plt.ylabel("Máº¥t mÃ¡t (Loss)")
plt.legend()
plt.grid(True)

with open("accuracy.json", "a") as file:
    json.dump({model.name: best_acc}, file, indent=4)

# Äá»™ chÃ­nh xÃ¡c (Accuracy)
plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss_info["train_acc"], label="Äá»™ chÃ­nh xÃ¡c huáº¥n luyá»‡n")
plt.plot(epochs_range, loss_info["test_acc"], label="Äá»™ chÃ­nh xÃ¡c kiá»ƒm tra")
plt.title("Biá»ƒu Ä‘á»“ Ä‘á»™ chÃ­nh xÃ¡c qua cÃ¡c epoch")
plt.xlabel("Epoch")
plt.ylabel("Äá»™ chÃ­nh xÃ¡c (Accuracy)")
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.savefig(f"images/{model.name}_training_curves.png", dpi=300)
plt.show()